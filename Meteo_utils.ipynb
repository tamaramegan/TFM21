{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meteo Station Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_meteo_zip(path, folder):\n",
    "    ### access files \n",
    "    ziplist = glob.glob(f'{path}/*.zip')\n",
    "    \n",
    "    ### access folder\n",
    "    zf = zipfile.ZipFile(f'{ziplist[folder]}')\n",
    "    \n",
    "    #extract dates of each of the zipfiles from file name\n",
    "    a = []\n",
    "    for i in range(len(zf.namelist())):\n",
    "        date_str = zf.namelist()[i].split('/')[1]\n",
    "        try:\n",
    "            date_date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "        except:\n",
    "            continue\n",
    "        a.append(date_date)\n",
    "        \n",
    "    # get unique values\n",
    "    unique_dates = list(set(a))\n",
    "    # order by date\n",
    "    unique_dates.sort()\n",
    "    #convert back to string\n",
    "    str_dates = []\n",
    "    for l in range(len(unique_dates)):\n",
    "        str_dates.append(unique_dates[l].strftime('%Y-%m-%d'))\n",
    "        \n",
    "    ## Reorder files\n",
    "    files_by_date = []\n",
    "    for dates in str_dates:\n",
    "        #r = re.compile(f'.*/{dates}/.*') # all files (including excel sheets)\n",
    "        r = re.compile(f'.*/{dates}/.*.csv') # only csv files\n",
    "        newlist = list(filter(r.match, zf.namelist())) \n",
    "        files_by_date.extend(newlist)\n",
    "    \n",
    "    return files_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_meteo_csv(path, folder, file): \n",
    "    ### access files \n",
    "    ziplist = glob.glob(f'{path}/*.zip')\n",
    "    \n",
    "    ### access folder\n",
    "    zf = zipfile.ZipFile(f'{ziplist[folder]}')\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(zf.open(file),header=None, encoding = 'latin-1')\n",
    "        print('Success regular csv, no header, latin encoding')\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_csv(zf.open(file), sep = ';', encoding = 'latin-1')\n",
    "            if len(df.columns) == 1:\n",
    "                df = df[df.columns[0]].str.split(',',expand=True)\n",
    "                df = df.iloc[1:]\n",
    "            print('Success sep \";\", latin encoding')\n",
    "        except:\n",
    "            print('Failed')\n",
    "    \n",
    "    ## Detect and elminate empty columns- incluiding columns with low number of values (<1% of file)\n",
    "    df = df.replace('', np.nan)\n",
    "    empty_cols = [col for col in df.columns if df[col].isnull().all() or round(df[col].isnull().value_counts()[0]/len(df[col]),2) < 0.01]\n",
    "    df.drop(empty_cols,\n",
    "        axis=1,\n",
    "        inplace=True)\n",
    "    if len(df.columns)==5:\n",
    "        df.columns = ['Date', 'Time','Variable', 'Value','Type']\n",
    "    \n",
    "    # add frequency as a variable\n",
    "    freq = ['1min','5min','1hora']\n",
    "    df['Freq']= re.findall('|'.join(freq),files_by_date[4])[0]\n",
    "    print(f'file ={file}, cols = {len(df.columns)}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get unique variable names\n",
    "def get_unique_variables(files_by_date, export_name):\n",
    "    summary_df = pd.DataFrame(columns = ['station','filename','colnum','colnames','nrows'])\n",
    "    for i in range(0,len(files_by_date)):\n",
    "    \n",
    "        df = read_meteo_csv(path =path,folder = 0,file =files_by_date[i])\n",
    "        if len(df.columns)==6:\n",
    "            colname = [list(df.Variable.unique())]\n",
    "        else:\n",
    "            colname= [list(df.columns)]\n",
    "        try:\n",
    "            filename=zip.namelist()[i].split('/')[2]\n",
    "        except:\n",
    "            filename=zip.namelist()[i].split('/')[1]\n",
    "        fill = {'station':zip.namelist()[i].split('/')[0].split(' ')[2],\n",
    "            'filename':filename,\n",
    "            'colnum':len(df.columns),\n",
    "            'colnames':colname,\n",
    "            'nrows':len(df)}\n",
    "        summary_df = summary_df.append(fill, ignore_index=True)\n",
    "    summary_df.to_csv(export_name) \n",
    "        \n",
    "    all_var = []\n",
    "    for i in range(0,len(summary_df)):\n",
    "        file_vars= summary_df.colnames[i][0]\n",
    "        not_in_list =list(set(file_vars) - set(all_var))\n",
    "        all_var.extend(not_in_list) \n",
    "    all_var = sorted([str(i) for i in all_var])\n",
    "    \n",
    "    return all_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
