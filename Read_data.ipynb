{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read meteorological data\n",
    "Folder with [original data](https://drive.google.com/drive/folders/1me2IpDY3om6IRKv_WMT5W6Qw0r9DI74C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import keplergl\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "from pyproj import Proj\n",
    "%run Meteo_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '07-HGPT-MT-07.- Estacion Aeropuerto-20210505T205931Z-001.zip',\n",
       " 'Estaciones_meteorologicas.csv',\n",
       " 'Estaciones_meteorologicas_SW.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños-20210426T162523Z-001.zip',\n",
       " 'Aeropuerto_5min.csv',\n",
       " '07-HGPT-MT-07-EstacionAeropuerto.csv',\n",
       " 'Inventario Estaciones Meteo.xls',\n",
       " '.ipynb_checkpoints',\n",
       " 'Estaciones_meteorologicas_SW.numbers',\n",
       " 'Aeropuerto_1min.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate data extraction from Drive downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/tamarahuete/Documents/Github_repos/TFM21/data'\n",
    "ziplist = glob.glob(f'{path}/*.zip')\n",
    "#ziplist = glob.glob(f'data/*.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/tamarahuete/Documents/Github_repos/TFM21/data/24-INAMHI-M0380.- HUambalo-20210610T152020Z-001.zip',\n",
       " '/Users/tamarahuete/Documents/Github_repos/TFM21/data/07-HGPT-MT-07.- Estacion Aeropuerto-20210505T205931Z-001.zip',\n",
       " '/Users/tamarahuete/Documents/Github_repos/TFM21/data/02-HGPT-MT-06.- Estacion Baños-20210426T162523Z-001.zip',\n",
       " '/Users/tamarahuete/Documents/Github_repos/TFM21/data/11-HGPT-PV-04.- Estacion Rio Verde-20210610T152008Z-001.zip']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ziplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24-INAMHI-M0380.- HUambalo/Todo.xls',\n",
       " '24-INAMHI-M0380.- HUambalo/2015/julio_diciembre.csv',\n",
       " '24-INAMHI-M0380.- HUambalo/2016/Enero_Abril.csv',\n",
       " '24-INAMHI-M0380.- HUambalo/Mayo-Octubre_subir.csv',\n",
       " '24-INAMHI-M0380.- HUambalo/Anual.xls']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile(f'{ziplist[0]}')\n",
    "zf.namelist()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_by_date = order_meteo_zip(path, folder =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success sep \";\", latin encoding\n",
      "file =24-INAMHI-M0380.- HUambalo/2015/julio_diciembre.csv, cols = 4\n"
     ]
    }
   ],
   "source": [
    "df = read_meteo_csv(path =path,folder = 0,file = files_by_date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>PAvg</th>\n",
       "      <th>Freq</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/07/2015 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/07/2015 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/07/2015 0:00</td>\n",
       "      <td>0,7</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/07/2015 0:00</td>\n",
       "      <td>2,5</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/07/2015 0:00</td>\n",
       "      <td>1,4</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fecha PAvg   Freq  \\\n",
       "0  01/07/2015 0:00    0  1hora   \n",
       "1  02/07/2015 0:00    0  1hora   \n",
       "2  03/07/2015 0:00  0,7  1hora   \n",
       "3  04/07/2015 0:00  2,5  1hora   \n",
       "4  05/07/2015 0:00  1,4  1hora   \n",
       "\n",
       "                                           file_name  \n",
       "0  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "1  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "2  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "3  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "4  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success regular csv, no header, latin encoding\n",
      "file =07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26/8310_1min_20170404.csv, cols = 6\n",
      "Success sep \";\", latin encoding\n",
      "file =07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26/Aeropuerto_1hora_20130517.csv, cols = 6\n",
      "Success regular csv, no header, latin encoding\n",
      "file =07-HGPT-MT-07.- Estacion Aeropuerto/2013-05-07/8310_1min_20170404.csv, cols = 6\n",
      "Success sep \";\", latin encoding\n",
      "file =07-HGPT-MT-07.- Estacion Aeropuerto/2013-05-07/Aeropuerto_5min_20140417.csv, cols = 6\n",
      "Success sep \";\", latin encoding\n",
      "file =07-HGPT-MT-07.- Estacion Aeropuerto/2013-06-13/Aeropuerto_5min_20130624.csv, cols = 6\n"
     ]
    }
   ],
   "source": [
    "all_var = get_unique_variables(files_by_date[0:5], export_name='summary_aeropuerto1.csv',path =path,folder = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATAvg',\n",
       " 'ATMax',\n",
       " 'ATMin',\n",
       " 'BAT',\n",
       " 'PAvg',\n",
       " 'RHAvg',\n",
       " 'RHMax',\n",
       " 'RHMin',\n",
       " 'TB1hrAcc',\n",
       " 'TB1minAcc',\n",
       " 'TB5minAcc',\n",
       " 'WDAvg',\n",
       " 'WDMax',\n",
       " 'WDMin',\n",
       " 'WSAvg',\n",
       " 'WSMax',\n",
       " 'WSMin']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Variable names:\n",
    "# What are 'TB1hrAcc','TB1minAcc','TB5minAcc','BAT'?\n",
    "\n",
    "replace_values ={\n",
    "# Temperature\n",
    "    'ATAvg' :['AT1HrAvg', 'AT5minAvg', 'ATAvg','Temperatura'],\n",
    "    'ATMin' : ['AT1HrMin', 'AT5minMin','T_Min'],\n",
    "    'ATMax' : ['AT1HrMax','AT5minMax', 'T_Max'],\n",
    " \n",
    " # Relative Humidity\n",
    "    'RHAvg' : ['Humedad','RH5minAvg','RHAvg','RelHumidAvg'],\n",
    "    'RHMin' : ['H_Min','RH5minMin','RelHumidMin'],\n",
    "    'RHMax' : ['H_Max', 'RH5minMax', 'RelHumidMax'],\n",
    "\n",
    " # Wind Speed\n",
    "    'WSAvg' : ['Velocidad','WS5minAvg','WSAvg','WindMnSpdSclr'],\n",
    "    'WSMin' : ['WindMinSpdSclr','WS5minMin'],\n",
    "    'WSMax' : ['WindMaxSpdSclr','WS5minMax'],\n",
    "\n",
    " # Wind Direction\n",
    "    'WDAvg' : ['Direccion', 'WDAvg','WD5minAvg','WindMnDirUnit'],\n",
    "    'WDMin' : ['WD5minMin'],\n",
    "    'WDMax' : ['WD5minMax','WindMaxDir'],\n",
    "\n",
    " # Rain\n",
    "    'PAvg' : ['Precipitacion']\n",
    "}\n",
    "\n",
    "var_list = ['ATAvg','ATMin','ATMax','RHAvg','RHMin','RHMax', 'WSAvg','WSMin','WSMax','WDAvg','WDMin', 'WDMax','PAvg','TB1hrAcc','TB1minAcc','TB5minAcc','BAT']\n",
    "sorted(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07-HGPT-MT-07-EstacionAeropuerto'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_by_date[1].split('/')[0].replace(\" \",\"\").replace(\".\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success regular csv, no header, latin encoding\n",
      "file =07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26/8310_1min_20170404.csv, cols = 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable\n",
       "Date_Time    datetime64[ns]\n",
       "Type                 object\n",
       "Freq                 object\n",
       "file_name            object\n",
       "ATAvg               float64\n",
       "ATMax               float64\n",
       "ATMin               float64\n",
       "BAT                 float64\n",
       "PAvg                float64\n",
       "RHAvg               float64\n",
       "RHMax               float64\n",
       "RHMin               float64\n",
       "TB1hrAcc            float64\n",
       "TB1minAcc           float64\n",
       "TB5minAcc           float64\n",
       "WDAvg               float64\n",
       "WDMax               float64\n",
       "WDMin               float64\n",
       "WSAvg               float64\n",
       "WSMax               float64\n",
       "WSMin               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_meteo_csv(path =path,folder = 0,file = files_by_date[0])\n",
    "df2 = reformat_df(df=df, replace_values=replace_values)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with 0, 26, 41\n",
    "master_df =pd.DataFrame()\n",
    "for file in range(0, len(files_by_date)):\n",
    "    print(f'{file}/{len(files_by_date)}')\n",
    "    df = read_meteo_csv(path =path,folder = 0,file = files_by_date[file])\n",
    "    df2 = reformat_df(df=df, replace_values=replace_values)\n",
    "    master_df = master_df.append(df2)\n",
    "master_df.to_csv(f'{files_by_date[file].split(\"/\")[0].replace(\" \",\"\").replace(\".\",\"\")}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv(f'{files_by_date[file].split(\"/\")[0].replace(\" \",\"\").replace(\".\",\"\")}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable\n",
       "Date_Time    datetime64[ns]\n",
       "Type                 object\n",
       "Freq                 object\n",
       "file_name            object\n",
       "ATAvg               float64\n",
       "ATMax               float64\n",
       "ATMin               float64\n",
       "BAT                 float64\n",
       "PAvg                float64\n",
       "RHAvg               float64\n",
       "RHMax               float64\n",
       "RHMin               float64\n",
       "TB1hrAcc            float64\n",
       "TB1minAcc           float64\n",
       "TB5minAcc           float64\n",
       "WDAvg               float64\n",
       "WDMax               float64\n",
       "WDMin               float64\n",
       "WSAvg               float64\n",
       "WSMax               float64\n",
       "WSMin               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4627314"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamarahuete/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(f'{files_by_date[file].split(\"/\")[0].replace(\" \",\"\").replace(\".\",\"\")}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date_Time', 'Type', 'Freq', 'file_name', 'ATAvg', 'ATMax', 'ATMin',\n",
       "       'BAT', 'PAvg', 'RHAvg', 'RHMax', 'RHMin', 'TB1hrAcc', 'TB1minAcc',\n",
       "       'TB5minAcc', 'WDAvg', 'WDMax', 'WDMin', 'WSAvg', 'WSMax', 'WSMin'],\n",
       "      dtype='object', name='Variable')"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Variable</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Type</th>\n",
       "      <th>Freq</th>\n",
       "      <th>file_name</th>\n",
       "      <th>ATAvg</th>\n",
       "      <th>ATMax</th>\n",
       "      <th>ATMin</th>\n",
       "      <th>BAT</th>\n",
       "      <th>PAvg</th>\n",
       "      <th>RHAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>RHMin</th>\n",
       "      <th>TB1hrAcc</th>\n",
       "      <th>TB1minAcc</th>\n",
       "      <th>TB5minAcc</th>\n",
       "      <th>WDAvg</th>\n",
       "      <th>WDMax</th>\n",
       "      <th>WDMin</th>\n",
       "      <th>WSAvg</th>\n",
       "      <th>WSMax</th>\n",
       "      <th>WSMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-19 21:18:00</td>\n",
       "      <td>G</td>\n",
       "      <td>1min</td>\n",
       "      <td>07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-19 21:19:00</td>\n",
       "      <td>G</td>\n",
       "      <td>1min</td>\n",
       "      <td>07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-19 21:20:00</td>\n",
       "      <td>G</td>\n",
       "      <td>1min</td>\n",
       "      <td>07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-19 21:21:00</td>\n",
       "      <td>G</td>\n",
       "      <td>1min</td>\n",
       "      <td>07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-19 21:22:00</td>\n",
       "      <td>G</td>\n",
       "      <td>1min</td>\n",
       "      <td>07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Variable           Date_Time Type  Freq  \\\n",
       "0        2013-03-19 21:18:00    G  1min   \n",
       "1        2013-03-19 21:19:00    G  1min   \n",
       "2        2013-03-19 21:20:00    G  1min   \n",
       "3        2013-03-19 21:21:00    G  1min   \n",
       "4        2013-03-19 21:22:00    G  1min   \n",
       "\n",
       "Variable                                          file_name  ATAvg  ATMax  \\\n",
       "0         07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...    NaN    NaN   \n",
       "1         07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...    NaN    NaN   \n",
       "2         07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...    NaN    NaN   \n",
       "3         07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...    NaN    NaN   \n",
       "4         07-HGPT-MT-07.- Estacion Aeropuerto/2013-03-26...    NaN    NaN   \n",
       "\n",
       "Variable  ATMin  BAT  PAvg  RHAvg  ...  RHMin  TB1hrAcc  TB1minAcc  TB5minAcc  \\\n",
       "0           NaN  NaN   NaN    NaN  ...    NaN       NaN        NaN        NaN   \n",
       "1           NaN  NaN   NaN    NaN  ...    NaN       NaN        NaN        NaN   \n",
       "2           NaN  NaN   NaN    NaN  ...    NaN       NaN        NaN        NaN   \n",
       "3           NaN  NaN   NaN    NaN  ...    NaN       NaN        NaN        NaN   \n",
       "4           NaN  NaN   NaN    NaN  ...    NaN       NaN        NaN        NaN   \n",
       "\n",
       "Variable  WDAvg  WDMax  WDMin  WSAvg  WSMax  WSMin  \n",
       "0           NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "1           NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2           NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3           NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4           NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other type of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/tamarahuete/Documents/Github_repos/TFM21/data'\n",
    "ziplist = glob.glob(f'{path}/*.zip')\n",
    "#ziplist = glob.glob(f'data/*.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/tamarahuete/Documents/Github_repos/TFM21/data/24-INAMHI-M0380.- HUambalo-20210610T152020Z-001.zip',\n",
       " '/Users/tamarahuete/Documents/Github_repos/TFM21/data/07-HGPT-MT-07.- Estacion Aeropuerto-20210505T205931Z-001.zip',\n",
       " '/Users/tamarahuete/Documents/Github_repos/TFM21/data/02-HGPT-MT-06.- Estacion Baños-20210426T162523Z-001.zip',\n",
       " '/Users/tamarahuete/Documents/Github_repos/TFM21/data/11-HGPT-PV-04.- Estacion Rio Verde-20210610T152008Z-001.zip']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ziplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-HGPT-MT-06.- Estacion Baños/2013-10-14/Banios_5min_20140116_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-07-28/BANIOS_5MIN_20160728_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-10-14/Banios_5min_20140116.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-02-06/8310_5min_20150211__.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-07-28/BANIOS_5MIN_20160728___.csv']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile(f'{ziplist[2]}')\n",
    "zf.namelist()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Revise this in the fucntion\n",
    "files_by_date = order_meteo_zip(path, folder =0)\n",
    "files_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02-HGPT-MT-06.- Estacion Baños/2013-10-14/Banios_5min_20140116_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-07-28/BANIOS_5MIN_20160728_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-10-14/Banios_5min_20140116.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-02-06/8310_5min_20150211__.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-07-28/BANIOS_5MIN_20160728___.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-01-14/8310_5min_20160125_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-06-13/8310_5min_20200203.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-01-14/8310_5min_20160125__.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-02-06/8310_5min_20150211_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-06-13/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-08-16/BANIOS_5MIN_20180816.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-02-06/8310_5min_20150211.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-10-14/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-07-28/BANIOS_5MIN_20160728.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-01-14/8310_5min_20160125.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-08-16/BANIOS_1MIN_20180816.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-02-06/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-11-25/Banos_5min_20141201.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2013-06-13.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2015-02-06.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2013-10-14.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2017-01-12.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-11-25/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2018-05-02.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2013-05-09.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-11-25/Banos_5min_20141201_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2013-03-21.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2018-01-08.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2018-08-16.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2016-08-24.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2013-10-04.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-11-25/Banos_5min_20141201_.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-05-09/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2014-11-25.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2017-08-16.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-04-11/BANIOS_5MIN_20160411__.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-01-14/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2016-01-14.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2014-05-08.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2015-07-08.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-04-11/BANIOS_5MIN_20160411_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-05-13/BANIOS_5MIN_20150513__.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-05-13/BANIOS_5MIN_20150513_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-07-08/8310_5min_20150714_.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-05-09/BAÑOS_1hora_20130326.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-04-11/BANIOS_5MIN_20160411.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-07-08/8310_5min_20150714_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2019-09-28/8310_5min_20190928.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2020-01-08.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2019-09-28.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-05-13/BANIOS_5MIN_20150513.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-03-21/BANIOS_5MIN_20180321_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-03-21/BANIOS_5MIN_20180321.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2018-06-14.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-03-21/BANIOS_5MIN_20180321_dato.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-07-08/8310_1min_20180508.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2019-06-20.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-01-08/8310_5min_20180116_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-01-08/8310_5min_20180116_datos.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-01-08/8310_5min_20180116_._.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-01-08/8310_5min_20180116_dato.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-07-08/8310_5min_20150714.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-06-14/8310_1min_20180618.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2019-01-18.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-05-08/Banos_5min_20131231_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2020-01-08/8310_1min_20200108.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-01-08/8310_5min_20180116.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2019-01-18/8310_1min_20190124.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-05-02/BANIOS_5MIN_201805030_dato.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2019-01-18/8310_5min_20190124.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-05-08/Banos_5min_20140514_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-01-08/8310_1min_20180116.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-05-02/BANIOS_5MIN_201805030_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2020-01-08/8310_5min_20200108.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-05-08/Banos_5min_20140514.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-10-04/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-06-14/8310_5min_20180618.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-05-08/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-10-07/BANIOS_5MIN_20151007_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-10-07/BANIOS_5MIN_20151007__.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-05-02/BANIOS_5MIN_201805030.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-10-04/Banos_5min_20130619.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2018-05-02/BANIOS_1MIN_20180502.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-01-12/8310_1min_20170123.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-01-12/8310_1min_20170123_1.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2015-10-07/BANIOS_5MIN_20151007.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-08-24/8310_5min_20161130_._.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-01-12/8310_1min_20170123_2.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-08-16/8310_5min_20170817_._.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-01-12/8310_1min_20170123_0.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/00_RESUMEN_1MIN_02/2013-07-31.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-07-24/Banos_5min_20140805.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-03-21/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-08-24/8310_5min_20161130.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-08-24/8310_5min_20161130_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2014-07-24/Banos_5min_20140805_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-07-31/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-08-16/8310_5min_20170817_subir.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-08-24/8310_1min_20161130_1.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-01-12/1min subir/8310_1min_20170717.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-08-16/8310_1min_20170817.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2019-09-28/8310_1min_20190928.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2017-08-16/8310_5min_20170817.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2019-06-20/8310_1min_20190624.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2013-07-31/8310_5min_20200203.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2019-06-20/8310_5min_20190624.csv',\n",
       " '02-HGPT-MT-06.- Estacion Baños/2016-08-24/8310_1min_20161130.csv']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## order files and skip resumen and xls sheets\n",
    "r = re.compile(f'.*/*/.*.csv') # only csv files\n",
    "files_by_date = list(filter(r.match, zf.namelist())) \n",
    "files_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-c7b7f3930b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_meteo_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles_by_date\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-a5265eabb1fc>\u001b[0m in \u001b[0;36mread_meteo_csv\u001b[0;34m(path, folder, file)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m## Detect and elminate empty columns- incluiding columns with low number of values (<1% of file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mempty_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     df.drop(empty_cols,\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "df = read_meteo_csv(path =path,folder = 0,file = files_by_date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>PAvg</th>\n",
       "      <th>Freq</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/07/2015 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/07/2015 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/07/2015 0:00</td>\n",
       "      <td>0,7</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/07/2015 0:00</td>\n",
       "      <td>2,5</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/07/2015 0:00</td>\n",
       "      <td>1,4</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>27/12/2015 0:00</td>\n",
       "      <td>2,40</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>28/12/2015 0:00</td>\n",
       "      <td>0,00</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>29/12/2015 0:00</td>\n",
       "      <td>0,00</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>30/12/2015 0:00</td>\n",
       "      <td>0,70</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>31/12/2015 0:00</td>\n",
       "      <td>0,00</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fecha  PAvg   Freq  \\\n",
       "0    01/07/2015 0:00     0  1hora   \n",
       "1    02/07/2015 0:00     0  1hora   \n",
       "2    03/07/2015 0:00   0,7  1hora   \n",
       "3    04/07/2015 0:00   2,5  1hora   \n",
       "4    05/07/2015 0:00   1,4  1hora   \n",
       "..               ...   ...    ...   \n",
       "179  27/12/2015 0:00  2,40  1hora   \n",
       "180  28/12/2015 0:00  0,00  1hora   \n",
       "181  29/12/2015 0:00  0,00  1hora   \n",
       "182  30/12/2015 0:00  0,70  1hora   \n",
       "183  31/12/2015 0:00  0,00  1hora   \n",
       "\n",
       "                                             file_name  \n",
       "0    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "1    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "2    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "3    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "4    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "..                                                 ...  \n",
       "179  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "180  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "181  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "182  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "183  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...  \n",
       "\n",
       "[184 rows x 4 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(['Date']) - set(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Type</th>\n",
       "      <th>Freq</th>\n",
       "      <th>file_name</th>\n",
       "      <th>ATAvg</th>\n",
       "      <th>ATMax</th>\n",
       "      <th>ATMin</th>\n",
       "      <th>BAT</th>\n",
       "      <th>PAvg</th>\n",
       "      <th>RHAvg</th>\n",
       "      <th>...</th>\n",
       "      <th>RHMin</th>\n",
       "      <th>TB1hrAcc</th>\n",
       "      <th>TB1minAcc</th>\n",
       "      <th>TB5minAcc</th>\n",
       "      <th>WDAvg</th>\n",
       "      <th>WDMax</th>\n",
       "      <th>WDMin</th>\n",
       "      <th>WSAvg</th>\n",
       "      <th>WSMax</th>\n",
       "      <th>WSMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1hora</td>\n",
       "      <td>24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_Time  Type   Freq  \\\n",
       "0   2015-01-07   NaN  1hora   \n",
       "1   2015-02-07   NaN  1hora   \n",
       "2   2015-03-07   NaN  1hora   \n",
       "3   2015-04-07   NaN  1hora   \n",
       "4   2015-05-07   NaN  1hora   \n",
       "..         ...   ...    ...   \n",
       "179 2015-12-27   NaN  1hora   \n",
       "180 2015-12-28   NaN  1hora   \n",
       "181 2015-12-29   NaN  1hora   \n",
       "182 2015-12-30   NaN  1hora   \n",
       "183 2015-12-31   NaN  1hora   \n",
       "\n",
       "                                             file_name  ATAvg  ATMax  ATMin  \\\n",
       "0    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "1    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "2    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "3    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "4    24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "179  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "180  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "181  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "182  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "183  24-INAMHI-M0380.- HUambalo/2015/julio_diciembr...    NaN    NaN    NaN   \n",
       "\n",
       "     BAT  PAvg  RHAvg  ...  RHMin  TB1hrAcc  TB1minAcc  TB5minAcc  WDAvg  \\\n",
       "0    NaN   0.0    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "1    NaN   0.0    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "2    NaN   0.7    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "3    NaN   2.5    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "4    NaN   1.4    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "..   ...   ...    ...  ...    ...       ...        ...        ...    ...   \n",
       "179  NaN   2.4    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "180  NaN   0.0    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "181  NaN   0.0    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "182  NaN   0.7    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "183  NaN   0.0    NaN  ...    NaN       NaN        NaN        NaN    NaN   \n",
       "\n",
       "     WDMax  WDMin  WSAvg  WSMax  WSMin  \n",
       "0      NaN    NaN    NaN    NaN    NaN  \n",
       "1      NaN    NaN    NaN    NaN    NaN  \n",
       "2      NaN    NaN    NaN    NaN    NaN  \n",
       "3      NaN    NaN    NaN    NaN    NaN  \n",
       "4      NaN    NaN    NaN    NaN    NaN  \n",
       "..     ...    ...    ...    ...    ...  \n",
       "179    NaN    NaN    NaN    NaN    NaN  \n",
       "180    NaN    NaN    NaN    NaN    NaN  \n",
       "181    NaN    NaN    NaN    NaN    NaN  \n",
       "182    NaN    NaN    NaN    NaN    NaN  \n",
       "183    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[184 rows x 21 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformat_df(df, replace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_df(df, replace_values):\n",
    "    \n",
    "    ## delete any empty rows\n",
    "    df.dropna(inplace=True)\n",
    "        \n",
    "    ## merge date + time\n",
    "    ## replace variable names\n",
    "    ## convert to long format with same column names and order\n",
    "    \n",
    "    #1. Wide format datasets\n",
    "    if len(list(set(['Date']) - set(df.columns))) == 1:\n",
    "        df['Date_Time'] = pd.to_datetime(df['Fecha'])\n",
    "        df.drop(columns =['Fecha'],inplace =True)\n",
    "        \n",
    "        for variable in list(replace_values.keys()):\n",
    "            try:\n",
    "                df = df.rename(columns={list(set(df.columns) & set(replace_values[variable]))[0]: variable})\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        df['Type'] = np.nan\n",
    "    \n",
    "    #2. Long format datasets\n",
    "    else:\n",
    "        df['Date_Time']= pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        df.drop(columns =['Date','Time'],inplace =True)\n",
    "        \n",
    "        for variable in list(replace_values.keys()):\n",
    "            df =df.replace(to_replace =replace_values[variable], value = variable)\n",
    "    \n",
    "        #Convert to long format and keep all variables\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df = df.reset_index().drop(columns = 'index')\n",
    "        freq = df.Freq.unique()[0]\n",
    "        file_name = df.file_name.unique()[0]\n",
    "        try:\n",
    "            df2 =df.pivot(index='Date_Time', columns='Variable').reset_index()\n",
    "            df = df.pivot(index='Date_Time', columns='Variable', values='Value').reset_index()\n",
    "        except:\n",
    "            df2 =pd.pivot_table(df,index='Date_Time', columns='Variable',aggfunc='first').reset_index()\n",
    "            df =pd.pivot_table(df,index='Date_Time', columns='Variable',values = 'Value',aggfunc='first').reset_index()\n",
    "        df['Freq'] = freq\n",
    "        df['Type'] = df2.Type.iloc[:,0]\n",
    "        df['file_name'] = file_name\n",
    "    \n",
    "    \n",
    "    ## Add variables that are not in the df but are in the general list\n",
    "    not_in_df = list(set(var_list)-set(df.columns))\n",
    "    for i in not_in_df:\n",
    "        df[i]=np.nan\n",
    "    \n",
    "    ## Order columns so all dfs have the same structure\n",
    "    var_order = ['Date_Time', 'Type', 'Freq','file_name']\n",
    "    var_order.extend(sorted(df.loc[:,list(set(df.columns) - set(['Date_Time', 'Type', 'Freq','file_name']))]))\n",
    "    df = df.reindex(var_order, axis=1)\n",
    "    \n",
    "    ## convert any ',' decimals to '.'\n",
    "    try:\n",
    "        df.iloc[:,4:] = df.iloc[:,4:].astype(float)\n",
    "    except:\n",
    "        cols= np.where(df.dtypes[4:]=='object')[0]+4\n",
    "        df.iloc[:,cols] = df.iloc[:,cols].apply(lambda x: x.str.replace(',','.')) \n",
    "        df.iloc[:,cols] = df.iloc[:,cols].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
